{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API for matching faces on self recorded video and Passport image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "\n",
    "from flask import Flask, jsonify, request\n",
    "import cv2\n",
    "import PIL\n",
    "import os\n",
    "import dlib\n",
    "import face_recognition\n",
    "import numpy \n",
    "import requests\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating function to convert images from recorded video and matches the frame image with passport image\n",
    "\n",
    "#assigning path\n",
    "path = os.getcwd()\n",
    "\n",
    "def face_recog(a,b):\n",
    "       \n",
    "    self_vid = cv2.VideoCapture(a)\n",
    "    success,image = self_vid.read()\n",
    "    count = 0\n",
    "    while success:\n",
    "        cv2.imwrite(\"static/frame%d.jpg\" % count, image)     # save frame as JPEG file      \n",
    "        success,image = self_vid.read()\n",
    "#         print('Read a new frame: ', success)\n",
    "        count += 1    \n",
    "    \n",
    "    #Image rotation of cell phone pictures\n",
    "    img = cv2.imread('static/frame0.jpg')\n",
    "    num_rows, num_cols = img.shape[:2]\n",
    "    rotation_matrix = cv2.getRotationMatrix2D((num_cols/2, num_rows/2), 90, 1)\n",
    "    img_rotation = cv2.warpAffine(img, rotation_matrix, (num_cols, num_rows))\n",
    "    cv2.imwrite(\"static/frame00.jpg\" ,img_rotation)  ## Saving images in folder 'static' in path\n",
    "\n",
    "      \n",
    "    #Face Recognition \n",
    "    img1 = 'static/frame00.jpg'\n",
    "    person1 = face_recognition.load_image_file(img1)\n",
    "    person1_face_encoding = face_recognition.face_encodings(person1)[0]\n",
    "#     display(\"Person-1\")\n",
    "#     display(Image(img1))\n",
    "\n",
    "#      img2 = b\n",
    "#     person2 = face_recognition.load_image_file(img2)\n",
    "    person2 = face_recognition.load_image_file(b)\n",
    "    person2_face_encoding = face_recognition.face_encodings(person2)[0]\n",
    "#     display(\"Person-2\")\n",
    "#     display(Image(img2))\n",
    "\n",
    "    #comparing 2 faces\n",
    "    results = face_recognition.compare_faces([person1_face_encoding], person2_face_encoding)\n",
    "\n",
    "    if results[0] == True:\n",
    "        result = \"Matched\"\n",
    "#         print(result)\n",
    "    else:\n",
    "        \n",
    "        result = \"Not matched\"\n",
    "#         print(result)      \n",
    "\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Function check\n",
    "# face_recog('static/vid1.mp4','static/img.jpg')\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnsupportedOperation",
     "evalue": "not writable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnsupportedOperation\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-8080888927c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'192.168.0.104'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# change with the IP address\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\flask\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, host, port, debug, load_dotenv, **options)\u001b[0m\n\u001b[0;32m    936\u001b[0m         \"\"\"Registers a blueprint on the application.\n\u001b[0;32m    937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 938\u001b[1;33m         \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mversionadded\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    939\u001b[0m         \"\"\"\n\u001b[0;32m    940\u001b[0m         \u001b[0mfirst_registration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\flask\\cli.py\u001b[0m in \u001b[0;36mshow_server_banner\u001b[1;34m(env, debug, app_import_path, eager_loading)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\click\\utils.py\u001b[0m in \u001b[0;36mecho\u001b[1;34m(message, file, nl, err, color)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m         \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m     \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnsupportedOperation\u001b[0m: not writable"
     ]
    }
   ],
   "source": [
    "# Creating API to take video and image as input and gives the face recognition match result\n",
    "\n",
    "app = Flask(__name__)\n",
    "@app.route('/VideoUploadAndValidate', methods=['POST'])\n",
    "def upload_file():\n",
    " \n",
    "    vid = request.files['vid']\n",
    "    img = request.files['img']\n",
    "    vid.save(path+\"//static//vid.mp4\")\n",
    "    img.save(path+\"//static//img.jpg\")\n",
    "\n",
    "    return jsonify({'Face Recognition':face_recog('static/vid.mp4','static/img.jpg')})\n",
    "\n",
    "\n",
    "app.run(host = '192.168.0.104',port=5000) # change with the IP address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
